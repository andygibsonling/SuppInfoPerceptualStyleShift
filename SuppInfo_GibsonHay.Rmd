---
title: "SupplementaryInfo_GibsonHay_LaS"
author: "Andy Gibson, Jen Hay"
date: "`r Sys.Date()`"
output: html_document
fontsize: 10
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Perceptual Style-shifting across Singing and Speech: Music activates Pop Song English for NZ Listeners

## Supplementary Materials
Andy Gibson and Jen Hay

## Contents
- This R Markdown file contains the code used for running the three models presented in the article, as well as for generating the plots.

1. Prerequisites
1. Read in Experiment 1 (PCT) data
1. Run Experiment 1 model
1. Plot Experiment 1 model predictions
1. Read in Experiment 2 (LDT) data
1. Run Experiment 2 accuracy model
1. Run Experiment 2 reaction time model
1. Plot Experiment 2 reaction time model predictions

## Prerequisites : load libraries
```{r load libraries etc, echo=T, message=F}
### load libraries ====
library(tidyverse) # data wrangling
library(lme4) # run models 
library(effects) # get model predictions
library(emmeans) # do pairwise analyses
library(lmerTest) # estimate p-values when summarising lmer models


# set up vif.mer function for later
vif.mer <- function (fit) {
  ## adapted from rms::vif
  
  v <- vcov(fit)
  nam <- names(fixef(fit))
  ## exclude intercepts
  ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
  if (ns > 0) {
    v <- v[-(1:ns), -(1:ns), drop = FALSE]
    nam <- nam[-(1:ns)]
  }
  
  d <- diag(v)^0.5
  v <- diag(solve(v/(d %o% d)))
  names(v) <- nam
  v
}


## set up a function for knitting model outputs tidily

tableify <- function(model) {
require(dplyr)
smry <- coef(summary(model)) %>% as.data.frame()
df <- smry %>%
mutate_at(c("Estimate", "Std. Error"), round, 5) %>%
mutate_at(vars(matches("[tz] value")), round, 3) %>%
mutate_at(vars(matches("^df$")), round, 0)
rownames(df) <- rownames(smry)
df
}




###  cool function from dan villareal's workshop on effects package and ggplot that let's you keep 
# levels of factors the way you want them.
df.eff <- function (x, row.names = NULL, optional = TRUE, transform = x$transformation$inverse, 
                    ...) {
  if (class(x)!="eff") stop("x must be of class eff")
  xx <- x$x
  for (var in names(xx)) {
    if (is.factor(xx[[var]])) {
      ##Fix the issue where levels(xx[[var]]!=(unique(xx[[var]])==levels(origDF[[var]])))
      xx[[var]] <- addNA(factor(xx[[var]], levels=unique(xx[[var]])))
    }
  }
  x$x <- xx
  result <- if (is.null(x$se)) 
    data.frame(x$x, fit = transform(x$fit))
  else data.frame(x$x, fit = transform(x$fit), se = x$se, 
                  lower = transform(x$lower), upper = transform(x$upper))
  attr(result, "transformation") <- transform
  result
}

```


# EXPERIMENT 1: PHONEME CATEGORISATION TASK (PCT)

## Read in Experiment 1 data

```{r read in PCT data and do manipulations}
dat1 <- read.csv("Data/PCT_rawData.csv")

# Let's swap the reference level for stimlength
dat1$StimLength <- as.factor(dat1$StimLength)
dat1$StimLength <- relevel(dat1$StimLength, ref = "Short")

```

For this analysis, we are only interested in music vs. non music. so we can set up specific contrast coding.
This contrast coding method comes from [here](https://stats.oarc.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/#User) and 
[here](https://marissabarlaz.github.io/portfolio/contrastcoding/#:~:text=By%20default%2C%20a%20variable%20does,or%20define%20any%20contrast%20manually)

Some relevant quotes from the 2nd link:
Another example of contrast coding would be, say we had three groups: English, Spanish, and French speakers, who participated in a lexical decision task. If we wanted to, we could compare between English and non-English (i.e., Spanish and French), and then between Spanish and French speakers. The contrast for that would look like this:
```{r} 
matrix(c(1, -1/2, -1/2, 0, .5, -.5), ncol = 2)
```
The intercept would be the grand mean. The first coefficient the model would produce would be the difference between the intercept and English mean, and also would be twice the difference between the intercept and the average of Spanish and French means. The second coefficient would be the difference between the French and Spanish speakers, divided by 2.

```{r PCT custom contrast coding}
# keep the original version with built-in treatment coding
dat1$ConditionTreatment <- as.factor(dat1$Condition)
# now make the version with custom contrasts
dat1$Condition <- as.factor(dat1$Condition)
mycontrasts2 = contrasts(dat1$Condition)
mycontrasts2[,1] = c(1, -1/2, -1/2)
mycontrasts2[,2] = c(0,.5,-.5)
colnames(mycontrasts2) <- c("Music_vs_NonMusic", "Noise_vs_Silence")
mycontrasts2
contrasts(dat1$Condition) = mycontrasts2
contrasts(dat1$Condition)
```


Get rid of outliers as per preregistration.  NB. nobody removed for having overall fast or slow reaction times, and none removed for 'onset delay' in eprime.

```{r remove outliers}

# drop all tokens where the reaction time is 3 by-speaker standard deviations
# above or below the by-speaker mean

# first get the mean and sd for each participant
dat1 %>% group_by(Participant) %>%summarise(meanRT = mean(RT), 
                                      sdRT = sd(RT)) -> means
# make the by-participant cut-offs outside 3 sds
means %>% mutate(topRT = meanRT + 3*sdRT, botRT = meanRT - 3*sdRT) -> means
# merge the cutoffs back into the main data
left_join(dat1,means) -> dat1
# remove those where RT is above the cutoff
dat1 %>% filter(RT < topRT) -> dat1 # 2592>2548 cut 44 trials
# remove those where RT is below the cutoff
dat1 %>% filter(RT > botRT) -> dat1 # 2548>2547 cut 1 trial
```



```{r look at raw data}
# creating raw data plot


# getting 95% confidence intervals

dat1 %>% group_by(Condition, StimStep) %>% 
  summarise(
    meanResp = mean(Response, na.rm = T), 
    sd = sd(Response, na.rm = T),
    n = n()) %>% 
  mutate(
    se = sd/sqrt(n),
    lower.ci = meanResp - qt(1 - (0.05 / 2), n - 1) * se,
    upper.ci = meanResp + qt(1 - (0.05 / 2), n - 1) * se) -> meanBad


# make a bit of horizontal space:
meanBad$StimStep <- ifelse(meanBad$Condition=="Music",meanBad$StimStep-0.05,meanBad$StimStep)
meanBad$StimStep <- ifelse(meanBad$Condition=="Silence",meanBad$StimStep+0.05,meanBad$StimStep)


### make min 0 and max 1
meanBad$lower.ci <- ifelse(meanBad$lower.ci < 0, 0, meanBad$lower.ci)
meanBad$upper.ci <- ifelse(meanBad$upper.ci > 1, 1, meanBad$upper.ci)

meanBad %>% ggplot(aes(y=meanResp, x=StimStep, colour = Condition, linetype=Condition,
                       ymin = lower.ci, ymax = upper.ci)) +
  geom_point() + 
  geom_line() +
  geom_errorbar(width=.1, linetype=1,alpha=0.3) + 
  scale_y_continuous("Mean proportion 'bad' responses", minor_breaks = NULL) +
  scale_x_continuous(
    name = "Stimulus step", breaks = 1:6, minor_breaks = NULL) +
  theme_bw(base_size = 16) +
  theme(axis.text.y = element_text(size=10), axis.text.x = element_text(size=12)) +
  scale_colour_brewer(palette = 'Dark2')

# save the plot if you like!
# ggsave('PCT_rawDataSummary.png', width=7, height=5.5)
```




## Run Experiment 1 model

```{r PCT model}

PCT_mod = glmer(Response ~ Condition * Trial24 +
              + StimStep + StimLength + PrevStimStep + (1|Participant), 
            data = dat1,  family = "binomial", glmerControl(optimizer = "bobyqa"))
#summary(PCT_mod) 
# 

# pretty knitting of model summary from Jen's funtion (see prerequisites section):
pctTable = tableify(PCT_mod)
knitr::kable(pctTable, caption="Model of PCT responses")

```

## Get a version of the model summary for latex
```{r latex, include=FALSE}
# get table for latex
xtable(summary(PCT_mod)[["coefficients"]], digits=3)

```


## PCT model to check the individual non-music conditions against music


```{r PCT model with treatment}

PCT_mod_Treatment = glmer(Response ~ ConditionTreatment * Trial24 +
              + StimStep + StimLength + PrevStimStep + (1|Participant), 
            data = dat1,  family = "binomial", glmerControl(optimizer = "bobyqa"))
#summary(PCT_mod_Treatment) 
# 

# pretty knitting of model summary from Jen's funtion (see prerequisites section):
pctTable = tableify(PCT_mod_Treatment)
knitr::kable(pctTable, caption="Model of PCT responses")

```

## Plot Experiment 1 model predictions

```{r plot Exp1}
### cond*trial
PCT_mod %>% 
  Effect(c("Condition","Trial24"), .) %>%   df.eff()

PCT_mod %>% 
  Effect(c("Condition","Trial24"), ., xlevels = 1000) %>% 
  df.eff() %>%
  ggplot(aes(x=Trial24, y=fit, group=Condition, colour=Condition, linetype = Condition, ymin=lower, ymax=upper)) +
  geom_path() +
  geom_errorbar(width=0, alpha = 0.05, linetype=1) +
  scale_y_continuous("Predicted probability of responding 'bad'", limits = c(0,1), minor_breaks = NULL) +
  scale_x_continuous('Trial number within each block', minor_breaks = NULL, limits = c(1,24), breaks = c(1,6,12,18,24), labels = c("1","6", "12","18", "24")) +
  theme_bw(base_size = 14) +
  theme(axis.text.y = element_text(size=10), axis.text.x = element_text(size=12)) +
  scale_colour_brewer(palette = 'Dark2')

# save the plot if you like!
# ggsave('PCT_mod.png', width=7, height=5.5)
  
```

# EXPERIMENT 2: LEXICAL DECISION TASK (LDT)

## Read in Experiment 2 (LDT) data

The data file should be in a folder called "Data" that is in the same location as this Rmd file.  Alternatively, you can change the path below yourself to find the file.


```{r readLDTdata}
dat2 <- read.csv("Data/LDT_rawData.csv")
```


We need to remove outliers and nonwords, log and scale some variables, and create custom contrast coding

### Remove outliers and nonwords
```{r outlierRemoval}
# drop all tokens with rt < 400ms
dat2 %>% filter(RT >399) -> dat2 # 55 items removed

# drop all tokens where the reaction time is 3 by-speaker standard deviations
# above the by-speaker mean

# first get the mean and sd for each participant
dat2 %>% group_by(Participant) %>%summarise(meanRT = mean(RT), 
                                      sdRT = sd(RT)) -> means
# make the by-participant cut-offs outside 3 sds
means %>% mutate(topRT = meanRT + 3*sdRT) -> means
# merge the cutoffs back into the main data
left_join(dat2,means) -> dat2
# remove those where RT is above the cutoff
dat2 %>% filter(RT < topRT) -> dat2 # cut 174 tokens, from 10745 to 10571

# get rid of all nonwords
dat2 %>% filter(StimulusType == "Word") -> dat2 # down to 5308 trials
```

### Manipulate variables
```{r manipulateVariables}
# log and scale RT, and the RT of the previous trial (PrevRT)
dat2$logRT <- log(dat2$RT)
# .lcs means logged, centred and scaled
dat2$RT.lcs <- scale(dat2$logRT)

dat2$logPrevRT <- log(dat2$PrevRT)
dat2$PrevRT.lcs <- scale(dat2$logPrevRT)
```



```{r customContrastCoding}
# keep the original version with built-in treatment coding
dat2$ConditionTreatment <- as.factor(dat2$Condition)
# now make the version with custom contrasts
dat2$Condition <- as.factor(dat2$Condition)
mycontrasts2 = contrasts(dat2$Condition)
mycontrasts2[,1] = c(1, -1/2, -1/2)
mycontrasts2[,2] = c(0,.5,-.5)
colnames(mycontrasts2) <- c("Music_vs_NonMusic", "Noise_vs_Silence")
mycontrasts2
contrasts(dat2$Condition) = mycontrasts2
contrasts(dat2$Condition)
```
## Run Experiment 2 accuracy model

```{r}
# model accuracy
LDT_Acc_mod <- glmer(Accuracy ~ Condition * Voice + (1|Participant) + (1|Word), data = dat2, family = 'binomial', glmerControl(optimizer = "bobyqa"))
#summary(LDT_Acc_mod)
###  converges.  no interaction of Condition by Voice.

# tried adding slope on subject for condition and voice separately.  doesn't converge with condition
# doesn't converge with a voice slope on both subject and word, or voice individually on either
#  no slopes

# pretty knitting of model summary from Jen's funtion (see prerequisites section):
ldtTable = tableify(LDT_Acc_mod)
knitr::kable(ldtTable, caption="Model of LDT Accuracy model")
```



## Run Experiment 2 reaction time model

Before we run the model for reaction time, we get rid of all the incorrect responses

```{r removeMistakes}
names(dat2)
dat2 %>% filter(Accuracy==1) -> dat2
```

Run RT model
```{r runRTmodel1}
LDT_RT_mod <- lmer(RT.lcs ~  Condition * Voice + PrevRT.lcs +
              (1 + PrevRT.lcs |Participant) + (1 + Voice | Word), 
              data = dat2)


# pretty knitting of model summary from Jen's funtion (see prerequisites section):
ldtTable = tableify(LDT_RT_mod)
knitr::kable(ldtTable, caption="Model of LDT RT model")
```
Condition and Voice interact: Music is different to non-music.


Check the VIF on the model
```{r LDT vif, message = F, results = 'hide'}
vif.mer(LDT_RT_mod)
```
The max vif = 1.99. No problematic collinearity.


Run a version of the model with treatment coding and Music condition as reference level
```{r run RT model 2}

LDT_RT_mod_Treatment <- lmer(RT.lcs ~  ConditionTreatment * Voice + PrevRT.lcs +
              (1 + PrevRT.lcs | Participant) + (1 + Voice | Word), 
              data = dat2)
summary(LDT_RT_mod_Treatment)

ldtTable2 = tableify(LDT_RT_mod_Treatment)
knitr::kable(ldtTable2, caption="Model of LDT RT model with treatment contrast coding")
```
Condition and Voice interact: The modulating effect of Voice on Condition is significantly different for both the non-music conditions as compared to music.


## Plot Experiment 2 reaction time model predictions
```{r Plot LDT}
##### PLOT IT!
# first we need to create a dataframe with Effect
effectsDF <- LDT_RT_mod %>% 
  Effect(c("Voice","Condition"), .) %>% 
  as.data.frame()  
### don't worry about the warning, that's just saying it's removed info about the scaling.

# backtransform the RT and standard errors to milliseconds scale
effectsDF$RT <- effectsDF$fit * attr(dat2$RT.lcs, 'scaled:scale') + attr(dat2$RT.lcs, 'scaled:center')
effectsDF$RT <- exp(effectsDF$RT)
effectsDF$lowerRT <- effectsDF$lower * attr(dat2$RT.lcs, 'scaled:scale') + attr(dat2$RT.lcs, 'scaled:center')
effectsDF$lowerRT <- exp(effectsDF$lowerRT)
effectsDF$upperRT <- effectsDF$upper * attr(dat2$RT.lcs, 'scaled:scale') + attr(dat2$RT.lcs, 'scaled:center')
effectsDF$upperRT <- exp(effectsDF$upperRT)

# make a version of voice that let's us see the error bars better
effectsDF$VoiceN <- as.numeric(effectsDF$Voice)
effectsDF$VoiceN <- ifelse(effectsDF$Condition=="Music", effectsDF$VoiceN -.03, effectsDF$VoiceN)
effectsDF$VoiceN <- ifelse(effectsDF$Condition=="Noise", effectsDF$VoiceN +.03, effectsDF$VoiceN)

# PLOT IT
effectsDF  %>%  ggplot(aes(x=VoiceN, y=RT, shape=Condition, colour=Condition, linetype = Condition, group = Condition,  ymin=lowerRT, ymax=upperRT)) +
  geom_line() +
  geom_errorbar(width = 0.05, alpha=0.2) +
  geom_point(data = effectsDF, aes(x = Voice), size =0) +
  geom_point(data = effectsDF, aes(x = VoiceN)) +
  scale_y_continuous('Reaction time (ms)', n.breaks = 6) +
  scale_x_discrete('Speaker country of origin') +
  theme_bw(base_size=16) + theme(axis.text.y = element_text(size = 10)) +
  scale_colour_brewer(palette = 'Dark2')
# ggsave('LDT_Model_LaS_20231215.png', width=7, height = 6)

```


